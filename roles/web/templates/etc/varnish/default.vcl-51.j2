#
# --- THIS FILE IS AUTOMATICALLY PROVISIONED THROUGH ANSIBLE ---
#

vcl 4.0;

import std;
{% if conf_varnish_import is defined %}{{ conf_varnish_import }}{% endif %}

###########
# Backend #
###########
{% if conf_varnish_backend_default is defined %}
backend default {
  {{ conf_varnish_backend_default }}
  {% if conf_mysql_flavour_debian_family == "percona-xtradb-cluster" %}
{{ conf_varnish_backend_probe_mysql_default }}
  {% else %}}
{{ conf_varnish_backend_probe_default }}
  {% endif %}
}
{% endif %}

{% if conf_varnish_backends is defined %}{{ conf_varnish_backends }}{% endif %}

#############
# ACL PURGE #
#############
acl purge {
  {{ conf_varnish_acl_purge }}}

  #
  # X-Forwarded-For
  #
  # See: https://www.varnish-cache.org/docs/2.1/faq/http.html
  #      % varnishlog | grep X-Forwarded-For
  #
  # We can have two scenarios actually:
  #
  #   REQUEST -> Varnish -> Apache2               (Varnish inserts X-Forwarded-For)
  #   REQUEST -> HAPROXY -> Varnish -> Apache2    (HAPROXY inserts X-Forwarded-For)
  #
  # In case Varnish is first in the chain, insert own X-Forwarded-For.
  # Boolean "conf_lbtier_enable", defined per node, tells us if we use HAPROXY.
  #

################
# sub vcl_hash #
################
sub vcl_hash {
  # Hash protocol and URL.
  hash_data(req.http.X-Forwarded-Proto);
  hash_data(req.url);

  # Hash host or server IP.
  if (req.http.host) {
      hash_data(req.http.host);
  } else {
      hash_data(server.ip);
  }

  {% if conf_varnish_vcl_hash is defined %}
    {{ conf_varnish_vcl_hash }}
  {% endif %}

  return (lookup);
}

{% if conf_varnish_vcl_init is defined %}
################
# sub vcl_init #
################
sub vcl_init {
  {{ conf_varnish_vcl_init }}
  return (ok);
}
{% endif %}

{% if conf_varnish_custom is defined %}
##########
# custom #
##########
{{ conf_varnish_custom }}
{% endif %}

################
# sub vcl_recv #
################
sub vcl_recv {

  # Allow purging.
  if (req.method == "PURGE") {
      if (req.http.X-Forwarded-For || !client.ip ~ purge) {
          return (synth(405, "This IP is not allowed to send PURGE requests."));
      }

      if (req.http.X-Purge-Method && req.http.X-Purge-Method ~ "(?i)regex") {
        ban("obj.http.X-Req-URL ~ " + req.url + " && obj.http.X-Req-Host == " + req.http.host);
        return (synth(200, "Ban added"));
      }

      # Force entry into vcl_hit() or vcl_miss() below and purge the actual cache.
      return (hash);
  }

  # Only deal with "normal" method requests. (http://book.varnish-software.com/3.0/VCL_Basics.html#default-vcl-recv)
  if (req.method != "GET" &&
      req.method != "HEAD" &&
      req.method != "PUT" &&
      req.method != "POST" &&
      req.method != "TRACE" &&
      req.method != "OPTIONS" &&
      req.method != "PATCH" &&
      req.method != "DELETE") {
      /* Non-RFC2616 or CONNECT which is weird. */
      return (pipe);
  }

  # Only cache GET or HEAD requests. This makes sure the POST requests are always passed. (http://book.varnish-software.com/3.0/VCL_Basics.html#default-vcl-recv)
  if (req.method != "GET" && req.method != "HEAD") {
      return (pass);
  }

  # Normalize Accept-Encoding header.
  if (req.http.Accept-Encoding) {
      if (req.url ~ "^[^?]*\.(7z|avi|bz2|docx|eot|flac|flv|gif|ico|gz|jpeg|jpg|mka|mkv|mov|mp3|mp4|mpeg|mpg|ogg|ogm|opus|pdf|png|pptx|rar|svgz|tbz|tgz|txz|webm|webp|woff2|xlsx|xz|zip)(\?.*)?$") {
          # No point in compressing these.
          unset req.http.Accept-Encoding;
      } elsif (req.http.Accept-Encoding ~ "gzip") {
          set req.http.Accept-Encoding = "gzip";
      } elsif (req.http.Accept-Encoding ~ "deflate") {
          set req.http.Accept-Encoding = "deflate";
      } else {
          # Unkown algorithm.
          unset req.http.Accept-Encoding;
      }
  }

  # Large static files should be piped, so they are delivered directly to the end-user without
  # waiting for Varnish to fully read the file first.
  if (req.url ~ "^[^?]*\.(7z|avi|bz2|flac|flv|gz|mka|mkv|mov|mp3|mp4|mpeg|mpg|ogg|ogm|opus|rar|tar|tgz|tbz|txz|wav|webm|xz|zip)(\?.*)?$") {
      unset req.http.Cookie;
      return (pipe);
  }

  # Remove all cookies for static files.
  if (req.url ~ "^[^?]*\.(bmp|css|csv|doc|docx|eot|gif|ico|jpeg|jpg|js|odt|otf|pdf|png|ppt|pptx|rtf|svg|svgz|swf|ttf|txt|webp|woff|woff2|xls|xlsx|xml)(\?.*)?$") {
      unset req.http.Cookie;
      return (hash);
  }

{% if conf_varnish_vcl_recv is defined %}
  {{ conf_varnish_vcl_recv }}
{% endif %}

  # Don't cache requests with authorization. (http://book.varnish-software.com/3.0/VCL_Basics.html#default-vcl-recv)
  #   if (req.http.Authorization) {
  #       return (pass);
  #   }

  return (hash);
}

############################
# sub vcl_backend_response #
############################
sub vcl_backend_response {
  set beresp.http.X-Req-Host = bereq.http.host;
  set beresp.http.X-Req-URL = bereq.url;

  # Strip any cookies before a static file is inserted into cache.
  if (bereq.url ~ "^[^?]*\.(bmp|css|csv|doc|docx|eot|gif|ico|jpeg|jpg|js|odt|otf|pdf|png|ppt|pptx|rtf|svg|svgz|swf|ttf|txt|webp|woff|woff2|xls|xlsx|xml)(\?.*)?$") {
     unset beresp.http.set-cookie;
  }

{% if conf_varnish_vcl_backend_response is defined %}
  {{ conf_varnish_vcl_backend_response }}
{% endif %}

  # Set 2min cache if unset for static files. (http://book.varnish-software.com/3.0/VCL_Basics.html#default-vcl-fetch)
  if (beresp.ttl <= 0s || beresp.http.Set-Cookie || beresp.http.Vary == "*") {
      set beresp.ttl = 120s;
      # set beresp.ttl = 120s;
      set beresp.uncacheable = true;
      return (deliver);
  }

  return (deliver);
}

###############
# sub vcl_hit #
###############
sub vcl_hit {
  # Called when a cache lookup is successful.

  if (obj.ttl >= 0s) {
    # A pure unadultered hit, deliver it
    return (deliver);
  }

  # https://www.varnish-cache.org/docs/trunk/users-guide/vcl-grace.html
  # When several clients are requesting the same page Varnish will send one request
  # to the backend and place the others on hold while fetching one copy from the backend. 
  # In some products this is called request coalescing and Varnish does this automatically.
  # If you are serving thousands of hits per second the queue of waiting requests can 
  # get huge. There are two potential problems - one is a thundering herd problem - 
  # suddenly releasing a thousand threads to serve content might send the load sky high.
  # Secondly - nobody likes to wait. To deal with this we can instruct Varnish to keep 
  # the objects in cache beyond their TTL and to serve the waiting requests somewhat 
  # stale content.

  # if (!std.healthy(req.backend_hint) && (obj.ttl + obj.grace > 0s)) {
  #   return (deliver);
  # } else {
  #   return (miss);
  # }

  # We have no fresh fish. Lets look at the stale ones.
  if (std.healthy(req.backend_hint)) {
    # Backend is healthy. Limit age to 10s.
    if (obj.ttl + 10s > 0s) {
      # set req.http.grace = "normal(limited)";
      return (deliver);
    } else {
      # No candidate for grace. Fetch a fresh object.
      return(miss);
    }
  } else {
    # backend is sick - use full grace
      if (obj.ttl + obj.grace > 0s) {
      #set req.http.grace = "full";
      return (deliver);
    } else {
      # no graced object.
      return (miss);
    }
  }

  # fetch & deliver once we get the result
  return (miss); # Dead code, keep as a safeguard
}

################
# sub vcl_miss #
################
sub vcl_miss {
  if (req.method == "PURGE") {
    #
    # This is now handled in vcl_recv.
    #
    # purge;
    return (synth(200, "Not in cache."));
  }

{% if conf_varnish_vcl_miss is defined %}
  {{ conf_varnish_vcl_miss }}
{% endif %}

  return (fetch);
}

################
# sub vcl_pass #
################
sub vcl_pass {
  if (req.method == "PURGE") {
      return (synth(502, "PURGE on a passed object"));
  }

{% if conf_varnish_vcl_pass is defined %}
  {{ conf_varnish_vcl_pass }}
{% endif %}

  return (fetch);
}

###################
# sub vcl_deliver #
###################
sub vcl_deliver {
  unset resp.http.X-Req-Host;
  unset resp.http.X-Req-URL;

  # If the page is already cached return a HIT header, otherwise MISS.
  if (obj.hits > 0) {
    set resp.http.X-Cache = "HIT";
    set resp.http.X-Cache-Hits = obj.hits;
  } else {
    set resp.http.X-Cache = "MISS";
  }

{% if conf_varnish_vcl_deliver is defined %}
  {{ conf_varnish_vcl_deliver }}
{% endif %}

  return (deliver);
}

{% if conf_varnish_vcl_synth is defined %}
#################
# sub vcl_synth #
#################
sub vcl_synth {
  {{ conf_varnish_vcl_synth }}
}
{% endif %}

{% if conf_varnish_vcl_backend_error is defined %}
#########################
# sub vcl_backend_error #
#########################
sub vcl_backend_error {
  {{ conf_varnish_vcl_backend_error }}
}
{% endif %}
